{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9QV0oDY0xzJ"
   },
   "source": [
    "## Tensors in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2fkP_np3Zpl"
   },
   "source": [
    "Adapted from notebook `02_Tensors` by Joe Papa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouTRyLS30xzL"
   },
   "source": [
    "Tensors are the main data format for Pytorch deep learning, and they are essentially the same as `numpy` arrays, and support the same kinds of operations, with a couple of notable exceptions:\n",
    "\n",
    "1. Sometimes functions have slightly a different syntax (e.g., <code>np.zeros((2,5))</code> vs. <code>torch.zeros(2,5)</code>.\n",
    "2. Tensors can represent scalars directly (not just via a one-element array)\n",
    "3. Tensors can keep track of changes to facilitate back-propagation (we won't have to worry about this)\n",
    "4. Tensors facilitate parallel computation when they are stored on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIAXms9fS1LA"
   },
   "source": [
    "# Creating Tensors\n",
    "\n",
    "Tensors are mostly the same as numpy arrays. For almost all your applications, tensors will hold floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8EKL4CN0xzM",
    "outputId": "820f9283-e562-4568-ca49-451d5f251f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "y = np.ones((2,5))\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHDeTeERR525",
    "outputId": "4e1c7510-fb3f-44b7-c290-88da54b43678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "\n",
      "tensor([[0.6924, 0.9653, 0.8391, 0.0475, 0.4451, 0.5401, 0.6464, 0.1467, 0.6108,\n",
      "         0.1003],\n",
      "        [0.2230, 0.3137, 0.5818, 0.7473, 0.3101, 0.2594, 0.9429, 0.4071, 0.9972,\n",
      "         0.8877],\n",
      "        [0.5655, 0.6921, 0.5836, 0.5450, 0.4879, 0.0840, 0.5243, 0.6857, 0.5096,\n",
      "         0.7114],\n",
      "        [0.7891, 0.2992, 0.4450, 0.4153, 0.1395, 0.8298, 0.7646, 0.8859, 0.6523,\n",
      "         0.8076],\n",
      "        [0.8990, 0.3842, 0.6025, 0.4057, 0.1272, 0.6045, 0.8039, 0.8829, 0.3003,\n",
      "         0.3251]])\n",
      "\n",
      "tensor([[0, 4, 3, 8, 0, 1, 9, 5, 7, 2],\n",
      "        [4, 3, 7, 7, 3, 9, 0, 5, 1, 1],\n",
      "        [2, 6, 8, 8, 2, 6, 9, 1, 9, 5],\n",
      "        [7, 7, 9, 3, 8, 0, 8, 9, 6, 1],\n",
      "        [3, 2, 3, 8, 7, 5, 4, 9, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Created from pre-existing arrays\n",
    "w = torch.tensor([1,2,3])              # from a list\n",
    "w = torch.tensor((1,2,3))              # from a tuple\n",
    "w = torch.tensor(x)                    # from a numpy array\n",
    "print(w)\n",
    "print()\n",
    "\n",
    "# Initialized by size\n",
    "w = torch.empty(2,5)         # uninitialized, elements values are not predictable\n",
    "w = torch.empty((2,5))       # can use same syntax as with numpy\n",
    "w = torch.zeros((2,5))        # all elements initialized with 0.0\n",
    "w = torch.ones(2,5)          # all elements initialized with 0.0\n",
    "print(w)\n",
    "print()\n",
    "\n",
    "# Initialized with same shape and type as another tensor, but with potentially different contents.\n",
    "w = torch.zeros_like(w)\n",
    "print(w)\n",
    "print()\n",
    "\n",
    "# Initialized by size with random values\n",
    "w = torch.rand(5,10)             # Creates a 100 x 200 tensor from a uniform distribution on [0, 1)\n",
    "print(w)\n",
    "print()\n",
    "\n",
    "w = torch.randn(5,10)            # Same but from a standard normal distribution\n",
    "w = torch.randint(0,10,(5,10))   # Same from uniformly choosen from [0,1,3,4,5,6,7,8,9]\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dIjg5_L0xzN"
   },
   "source": [
    "Exploring the attributes of a tensor is similar to numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2uuLTtR0xzN",
    "outputId": "92525fa0-7566-401c-ebc6-d1c15089318d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n",
      "torch.int64\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(w.size())\n",
    "print(w.dtype)\n",
    "print(w.ndim)      # how many dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN3pvGMl0xzN"
   },
   "source": [
    "As mentioned, tensors can also hold scalar values in a way that is consistent with array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCK4kmzH0xzO",
    "outputId": "232642da-ce81-4c87-dfce-98cd1bd54ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10)\n",
      "\n",
      "tensor(20)\n",
      "\n",
      "tensor(100)\n",
      "\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(10)          #  This is the constructor\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "y = 2 * x                     #  You can do ordinary arithmetic on tensors\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "print(x*x)\n",
    "print()\n",
    "\n",
    "print( x.item() )             #  This is how to extract the numeric value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvwi0dyuTZFA"
   },
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zy_IzoICSt_E",
    "outputId": "63efd3f5-7c7a-41f1-a067-00030ab62e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Specify data type at creation using dtype\n",
    "w = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "\n",
    "# Use casting method to cast to a new data type\n",
    "w.int()       # w remains a float32 after cast\n",
    "w = w.int()   # w changes to int32 after cast\n",
    "\n",
    "# Use to() method to cast to a new type\n",
    "w = w.to(torch.float64) # <1>\n",
    "w = w.to(dtype=torch.float64) # <2>\n",
    "\n",
    "# Python automatically converts data types during operations\n",
    "x = torch.tensor([1,2,3], dtype=torch.int32)\n",
    "y = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "z = x + y                                       # x is converted to float32 before adding\n",
    "\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLvRdCYET-cG"
   },
   "source": [
    "## Tensor Operations: indexing, slicing, transposing, and aggregating\n",
    "\n",
    "These are essentially the same as with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnLlmRdwTesO",
    "outputId": "a0fb7f17-6848-4560-d8c5-def2f8a6a532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "tensor(5)\n",
      "\n",
      "5\n",
      "\n",
      "tensor([2, 5])\n",
      "\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "\n",
      "tensor([1, 2, 3, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# Indexing, returns a tensor\n",
    "print(x[1,1])\n",
    "print()\n",
    "\n",
    "# Indexing, returns value as Python number\n",
    "print(x[1,1].item())\n",
    "print()\n",
    "\n",
    "# Slicing\n",
    "print(x[:2,1])\n",
    "print()\n",
    "\n",
    "print(x[:-1,:])\n",
    "print()\n",
    "\n",
    "# Boolean indexing:  Only keep elements less than 5\n",
    "print(x[x<5])\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqXM3ECQ53_h",
    "outputId": "c3e2f0c9-6ddb-4cfd-eb62-0005802a63a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  4,  7, 10],\n",
      "        [ 2,  5,  8, 11],\n",
      "        [ 3,  6,  9, 12]])\n",
      "\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
      "\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
      "\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transpose array, x.t() or x.T can be used\n",
    "print(x.t())\n",
    "print()\n",
    "\n",
    "# Changing shape, Usually view() is preferred over reshape()\n",
    "print(x.view((2,6)))   # must have the same number of elements\n",
    "print()\n",
    "\n",
    "print(x)                      # does not change shape of original, so assign if you want a new shape\n",
    "print()\n",
    "\n",
    "# flattening tensors\n",
    "a = x.flatten()\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "print(x.view(12))   # another way to do it\n",
    "print()\n",
    "\n",
    "print(x.view(-1))   # weird, but you'll see this too:\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqu402op0xzP",
    "outputId": "916f7f10-89d2-4afe-e949-6ca82484d516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "\n",
      "tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "        [ 4,  5,  6,  4,  5,  6],\n",
      "        [ 7,  8,  9,  7,  8,  9],\n",
      "        [10, 11, 12, 10, 11, 12]])\n",
      "\n",
      "tensor([1, 2, 3]) tensor([4, 5, 6]) tensor([7, 8, 9]) tensor([10, 11, 12])\n",
      "\n",
      "tensor([ 1,  4,  7, 10]) tensor([ 2,  5,  8, 11]) tensor([ 3,  6,  9, 12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combining tensors\n",
    "y = torch.stack((x, x))\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "z = torch.hstack((x, x))\n",
    "print(z)\n",
    "print()\n",
    "\n",
    "# Splitting tensors\n",
    "a,b,c,d = x.unbind(dim=0)\n",
    "print(a,b,c,d)\n",
    "print()\n",
    "a,b,c = x.unbind(dim=1)\n",
    "print(a,b,c)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbzMwCbOLF4T"
   },
   "source": [
    "## Devices:  CPU\n",
    "\n",
    "If you do nothing, all your data will be stored in your cpu's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWv6NA5YKpLU",
    "outputId": "d8555c17-c924-41c1-e9f9-a2eb451a142c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 10, 12],\n",
      "        [14, 16, 18]])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.tensor([[7,8,9],[10,11,12]])\n",
    "z = x + y\n",
    "print(z)\n",
    "\n",
    "print(z.device)     # each tensor has an attribute telling where it is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cvJwOfpRjyp"
   },
   "source": [
    "## Devices: GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lB62TcNkQpjn",
    "outputId": "6aea7814-ae5f-4948-9a54-cb3682606f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "tensor([[ 8, 10, 12],\n",
      "        [14, 16, 18]], device='cuda:0')\n",
      "\n",
      "torch.Size([2, 3])\n",
      "\n",
      "cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standard way to assign a GPU if is available (e.g., on Collab)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "print()\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6]   ], device=device)   # you can specify a device in a constructor\n",
    "y = torch.tensor([[7,8,9],[10,11,12]], device=device)\n",
    "z = x + y\n",
    "print(z)\n",
    "print()\n",
    "print(z.size())\n",
    "print()\n",
    "print(z.device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siupc0FJR0ma"
   },
   "source": [
    "## Moving Tensors between CPU & GPU\n",
    "\n",
    "You can NOT perform arithmetic when operands are in different devices. So you will have to move\n",
    "data back and forth sometimes (e.g., you want to do batch computations on the GPU but otherwise\n",
    "use your local cpu).\n",
    "\n",
    "You can print out data from the GPU, however!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "U5yCYvynR1md",
    "outputId": "29f5e8a3-98b3-4c2d-97ac-47e79ccdb022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "cuda:0 cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5181ffa1b8f2>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "print()\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6]   ],device=device)   # you can specify a device in a constructor\n",
    "y = torch.tensor([[7,8,9],[10,11,12]])\n",
    "\n",
    "print(x.device, y.device)\n",
    "\n",
    "z = x + y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRh2KPUV6Zx8",
    "outputId": "1a0457e9-8ae6-416a-85e8-4d966f7d856c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cpu\n",
      "cuda:0 cuda:0\n",
      "tensor([[ 8, 10, 12],\n",
      "        [14, 16, 18]], device='cuda:0')\n",
      "tensor([[ 8, 10, 12],\n",
      "        [14, 16, 18]])\n"
     ]
    }
   ],
   "source": [
    "# you can convert to a new device temporarily\n",
    "\n",
    "z = x + y.to(device)\n",
    "\n",
    "print(x.device, y.device)\n",
    "\n",
    "# or permanently\n",
    "\n",
    "y = y.to(device)                 # remember to reassign it, otherwise the device is not changed\n",
    "\n",
    "print(x.device, y.device)\n",
    "\n",
    "z = x + y\n",
    "\n",
    "print(z)\n",
    "\n",
    "print(z.to('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgOXsLcf8qD9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMrgRfEw8qUp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
